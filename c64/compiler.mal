enum OpCode
{
    OpNone,
    OpPrint,
    OpAdd,
    OpSubtract,
    OpMultiply,
    OpDivide,
    OpNegate,
    OpNot,
    OpConstant,
    OpPrint,
    OpPop,
    OpGetVariable,
    OpSetVariable,
    OpGoto,
    OpEqual,
    OpJumpIfFalse,
    OpLess,
    OpLessEqual,
    OpGreater,
    OpGreaterEqual,
    OpConcat,
    OpInput,
    OpReturn
}

enum Precedence
{
    None,
    Assignment,
    Or,
    And,
    Equality,
    Comparison,
    Term,
    Factor,
    Unary,
    Call,
    Primary
}

// placeholder
//fn num(value) => value

class Instruction
{
    init(line_number)
    {
        me.op = OpCode.OpNone
        me.operand = 0
        me.line_number = line_number
    }

    writeByte(op)
    {
        me.op = op
    }

    writeBytes(op, operand)
    {
        me.op = op
        me.operand = operand
    }

    toString()
    {
        const ops = ["OpNone",
            "OpPrint",
            "OpAdd",
            "OpSubtract",
            "OpMultiply",
            "OpDivide",
            "OpNegate",
            "OpConstant",
            "OpPrint",
            "OpPop",
            "OpGetVariable",
            "OpSetVariable",
            "OpGoto",
            "OpEqual",
            "OpJumpIfFalse",
            "OpLess",
            "OpLessEqual",
            "OpGreater",
            "OpGreaterEqual",
            "OpConcat",
            "OpInput",
            "OpReturn"]
        return "%{me.line_number} %{OpCode.name(me.op)} %{me.operand}"
    }
}

class Chunk
{
    init()
    {
        me.instructions = []
        me.line_number = 0
    }

    setLine(line_number)
    {
        me.line_number = num(line_number)
    }

    writeByte(op)
    {
        const instr = Instruction(me.line_number)
        instr.writeByte(op)
        me.instructions << instr
    }

    writeBytes(op, operand)
    {
        const instr = Instruction(me.line_number)
        instr.writeBytes(op, operand)
        me.instructions << instr
    }
}

class ParseRule
{
    init(token, prefix, infix, precedence)
    {
        me.token = token
        me.prefix = prefix
        me.infix = infix
        me.precedence = precedence
    }
}

class Compiler
{
    init(tokens)
    {
        me.tokens = tokens;
        me.current = tokens[0]
        me.chunk = Chunk()
        me.token_index = 0
        me.had_error = false
        me.rules = [
            ParseRule(TokenType.None, false, false, Precedence.None),
            ParseRule(TokenType.Input, false, false, Precedence.None),
            ParseRule(TokenType.Print, false, false, Precedence.None),
            ParseRule(TokenType.Goto, false, false, Precedence.None),
            ParseRule(TokenType.If, false, false, Precedence.None),
            ParseRule(TokenType.Then, false, false, Precedence.None),
            ParseRule(TokenType.Not, me.not, false, Precedence.None),
            ParseRule(TokenType.LessEqual, false, me.binary, Precedence.Comparison),
            ParseRule(TokenType.GreaterEqual, false, me.binary, Precedence.Comparison),
            ParseRule(TokenType.Less, false, me.binary, Precedence.Comparison),
            ParseRule(TokenType.Greater, false, me.binary, Precedence.Comparison),
            ParseRule(TokenType.Equals, false, me.binary, Precedence.Equality),
            ParseRule(TokenType.Plus, false, me.binary, Precedence.Term),
            ParseRule(TokenType.Minus, me.unary, me.binary, Precedence.Term),
            ParseRule(TokenType.Times, false, me.binary, Precedence.Factor),
            ParseRule(TokenType.Divide, false, me.binary, Precedence.Factor),
            ParseRule(TokenType.LeftParan, me.grouping, false, Precedence.None),
            ParseRule(TokenType.RightParan, false, false, Precedence.None),
            ParseRule(TokenType.SemiColon, false, false, Precedence.None),
            ParseRule(TokenType.Colon, false, false, Precedence.None),
            ParseRule(TokenType.Comma, false, false, Precedence.None),
            ParseRule(TokenType.Identifier,  me.variable, false, Precedence.None),
            ParseRule(TokenType.String,  me.string, false, Precedence.None),
            ParseRule(TokenType.Number, me.number, false, Precedence.None),
            ParseRule(TokenType.Error, false, false, Precedence.None),
            ParseRule(TokenType.Eof,  false, false, Precedence.None)
        ]
    }

    endCompiler()
    {
        me.chunk.writeByte(OpCode.OpReturn)
    }

    compile()
    {
        me.advance()
        
        while (!me.match(TokenType.Eof)) do
        {
            me.chunk.setLine(me.current.line_number)
            me.declaration()
        }
            

        me.endCompiler()

        return me.chunk
    }

    declaration()
    {
        me.statement()
    }

    expressionStatement()
    {
        me.expression(false)
        me.chunk.writeByte(OpCode.OpPop)
    }

    gotoStatement()
    {
        me.consume(TokenType.Number, "?SYNTAX ERROR - line number expected")
        me.chunk.writeBytes(OpCode.OpGoto, num(me.previous().lexeme))
    }

    ifStatement()
    {
        me.expression(true)
        if me.match(TokenType.Then) then
        {
            me.chunk.writeByte(OpCode.OpJumpIfFalse)
            if me.check(TokenType.Number) then
                me.gotoStatement()
            else
                me.statement()
        }
        else if me.match(TokenType.Goto) then
        {
            me.chunk.writeByte(OpCode.OpJumpIfFalse)
            me.gotoStatement()
        }
    }

    statement()
    {
        if me.match(TokenType.Print) then 
            me.printStatement()
        else if me.match(TokenType.Goto) then
            me.gotoStatement()
        else if me.match(TokenType.If) then
            me.ifStatement()
        else if me.match(TokenType.Input) then
            me.inputStatement()
        else
            me.expressionStatement()
    }

    inputStatement()
    {
        
        if me.match(TokenType.String) then
        {
            me.string(false)
            me.chunk.writeBytes(OpCode.OpPrint, "")
            me.consume(TokenType.SemiColon, "?SYNTAX ERROR")
        }
        me.match(TokenType.Identifier)
        const name = me.previous().lexeme
        me.chunk.writeBytes(OpCode.OpInput, false)
        me.chunk.writeBytes(OpCode.OpSetVariable, name)

        while me.match(TokenType.Comma) do
        {
            me.consume(TokenType.Identifier, "?SYNTAX ERROR")
            const name = me.previous().lexeme
            me.chunk.writeBytes(OpCode.OpInput, true)
            me.chunk.writeBytes(OpCode.OpSetVariable, name)
        }
    }

    printStatement()
    {
        var trailing = "\n"
        me.expression(true)
        while me.match(TokenType.SemiColon) or me.match(TokenType.Comma) or !me.endOfLine() do
        {
            //print "current: %{me.current.toString()}"
            const isComma = me.previous().token_type == TokenType.Comma
            if !me.endOfLine() then
            {
                me.expression(true)
                me.chunk.writeBytes(OpCode.OpConcat, isComma)
            }
            else
            {
                if isComma then trailing = "\t" else trailing = ""
            }
            
        }
        me.chunk.writeBytes(OpCode.OpPrint, trailing)
    }

    endOfLine() => (me.current.line_number != me.previous().line_number) or me.check(TokenType.Eof)

    match(type)
    {
        if !me.check(type) then return false
        me.advance()
        return true
    }

    check(type)
    {
        return me.current.token_type == type
    }

    advance()
    {
        if me.token_index >= len(me.tokens) then return

        me.current = me.tokens[me.token_index++]
        //me.chunk.setLine(me.current.line_number)
        if me.current != TokenType.Error then return
        me.error("?SYNTAX ERROR - error token")
    }

    previous()
    {
        return me.tokens[me.token_index-2]
    }

    expression(dontAssign)
    {
        me.parsePrecedence(Precedence.Assignment, dontAssign)
    }

    parsePrecedence(precedence, dontAssign)
    {
        me.advance()
        //print "Check rule for token: %{me.previous().token_type}"
        const prefixRule = me.getRule(me.previous().token_type).prefix
        //print "Prefix rule: %{prefixRule}"
        if (!prefixRule) then 
        { 
            me.error("?SYNTAX ERROR - no prefix rule")
            return
        }
        var canAssign = precedence <= Precedence.Assignment and !dontAssign
        prefixRule(canAssign)
        //print "after prefix rule token: %{me.current.token_type}"
        while precedence <= me.getRule(me.current.token_type).precedence do
        {
            //print "parsing precedence"
            me.advance()
            const infixRule = me.getRule(me.previous().token_type).infix 
            infixRule(canAssign)
        }
    }

    getRule(type)
    {
        // this is slow, but hey it's a c64, and safer than having to keep the indexes of the list in line
        //const rule = me.rules[type] 
        const rule = me.rules where x => x.token == type
        //print "rule: %{rule.token}"

        return rule[0]
    }

    not(canAssign)
    {
        const op = me.previous().token_type

        me.expression(true)
        me.chunk.writeByte(OpCode.OpNot)
    }

    unary(canAssign)
    {
        const op = me.previous().token_type

        me.parsePrecedence(Precedence.Unary, true)
        me.chunk.writeByte(OpCode.OpNegate)

        //if op == TokenType.Minus then 
        //    me.chunk.writeByte(OpCode.OpNegate)
        //else if op == TokenType.Not then
        //    me.chunk.writeByte(OpCode.OpNot)
        
    }

    binary(canAssign)
    {
        const op = me.previous().token_type
        const rule = me.getRule(op)
        me.parsePrecedence(rule.precedence+1, false)

        if op == TokenType.Plus then me.chunk.writeByte(OpCode.OpAdd)
        if op == TokenType.Minus then me.chunk.writeByte(OpCode.OpSubtract)
        if op == TokenType.Times then me.chunk.writeByte(OpCode.OpMultiply)
        if op == TokenType.Divide then me.chunk.writeByte(OpCode.OpDivide)
        if op == TokenType.Equals then me.chunk.writeByte(OpCode.OpEqual)

        if op == TokenType.Less then me.chunk.writeByte(OpCode.OpLess)
        if op == TokenType.LessEqual then me.chunk.writeByte(OpCode.OpLessEqual)
        if op == TokenType.Greater then me.chunk.writeByte(OpCode.OpGreater)
        if op == TokenType.GreaterEqual then me.chunk.writeByte(OpCode.OpGreaterEqual)
    }

    number(canAssign)
    {
        const token = me.previous()
        const number = num(token.lexeme)
        me.chunk.writeBytes(OpCode.OpConstant, number)
    }

    string(canAssign)
    {
        const token = me.previous()
        me.chunk.writeBytes(OpCode.OpConstant, token.lexeme)
    }

    grouping(canAssign)
    {
        me.expression(false)
        me.consume(TokenType.RightParan,"?SYNTAX ERROR - grouping")
    }

    variable(canAssign)
    {
        const name = me.previous().lexeme
        if canAssign and me.match(TokenType.Equals)  then
        {
            me.expression(false)
            me.chunk.writeBytes(OpCode.OpSetVariable, name)
        }
        else
        {
            me.chunk.writeBytes(OpCode.OpGetVariable, name)
        }
        
    }

    consume(type, message)
    {
        if me.current.token_type == type then
        {
            me.advance()
            return
        }
        me.error(message)
    }

    error(message)
    {
        me.had_error = true
        print message
    }
}
